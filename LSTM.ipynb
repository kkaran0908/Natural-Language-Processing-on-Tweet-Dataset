{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "FP8yM1gF2vf9",
    "outputId": "c26c58f2-c683-452d-e274-657f3023dd86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "1ariD0w52-JG",
    "outputId": "a5d55d7c-b692-4988-dcda-c531793dafd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_test_r50.npy',\n",
       " 'x_train_r50.npy',\n",
       " 'y_test.npy',\n",
       " 'y_train.npy',\n",
       " 'Evaluation Model.ipynb',\n",
       " 'maskrcnn',\n",
       " 'test.txt',\n",
       " 'train.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('drive/My Drive/Fake Image Detection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "miXDZgt_2vgC"
   },
   "outputs": [],
   "source": [
    "# read file from google-drive, colab doesnt keeps uploaded files persistently\n",
    "\n",
    "tweet_file = open(r\"drive/My Drive/Fake Image Detection/train.txt\", encoding=\"utf8\")\n",
    "tweets = tweet_file.read()\n",
    "\n",
    "# test file separate\n",
    "tweets_file_test = open(r\"drive/My Drive/Fake Image Detection/test.txt\", encoding=\"utf8\")\n",
    "tweets_test = tweets_file_test.read()\n",
    "\n",
    "# tweets_list = nltk.sent_tokenize(tweets)\n",
    "tweets_list = re.split('\\n\\n',tweets)\n",
    "tweets_list_test = re.split('\\n\\n',tweets_test)\n",
    "\n",
    "tweets_list = tweets_list[:-1]\n",
    "tweets_list_test = tweets_list_test[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ihQVd0Hj2vgE",
    "outputId": "750edc6d-dfbd-47fd-8cca-e2af3643956f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean train dataset\n",
    "tweets_clean_list = []\n",
    "sentiments_list = []\n",
    "\n",
    "for sent in tweets_list:\n",
    "  # remove \\n\n",
    "  temp = re.sub(\"\\n\", ' ', sent)\n",
    "\n",
    "  # remove ’\n",
    "  temp = re.sub(\"\\’\", '', sent)\n",
    "\n",
    "  # convert to lowercase\n",
    "  temp = temp.lower()\n",
    "\n",
    "  # remove unnecessary punctuations\n",
    "  temp = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in temp]).split())\n",
    "  \n",
    "  # remove first two words from the message, its metadata\n",
    "  temp = temp.split(' ', 3)\n",
    "\n",
    "  # take the next word as sentiment\n",
    "  sentiment = temp[2]\n",
    "\n",
    "  # Retreive only the message\n",
    "  new_msg = temp[3]\n",
    "\n",
    "  new_msg = new_msg.replace(\"hin\", \"\")\n",
    "  new_msg = new_msg.replace(\"eng\", \"\")\n",
    "  new_msg = new_msg.replace(\"o\", \"\")\n",
    "\n",
    "  # emoji removal by emoji pattern\n",
    "  emoji_pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "  new_msg = emoji_pattern.sub(r'', new_msg)\n",
    "\n",
    "  # remove multiple consecutive spaces from message\n",
    "  new_msg = re.sub(' +', ' ', new_msg)\n",
    "\n",
    "  #after cleaning up, append to new list\n",
    "  tweets_clean_list.append(new_msg)\n",
    "  sentiments_list.append(sentiment)\n",
    "\n",
    "tweets_clean_list[:10]\n",
    "sentiments_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Ij0sTeC_2vgG",
    "outputId": "e6e6c237-6535-4708-af0c-be40194a0f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Clean Test dataset\\\n",
    "#def hello():\n",
    "tweets_clean_list_test = []\n",
    "sentiments_list_test = []\n",
    "\n",
    "for sent in tweets_list_test:\n",
    "  # remove \\n\n",
    "    temp = re.sub(\"\\n\", ' ', sent)\n",
    "\n",
    "  # remove ’\n",
    "    temp = re.sub(\"\\’\", '', sent)\n",
    "\n",
    "  # remove unnecessary punctuations\n",
    "    temp = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in temp]).split())\n",
    "  \n",
    "  # remove first three words from the message, its metadata\n",
    "    temp = temp.split(' ', 3)\n",
    "\n",
    "  # take the next word as sentiment\n",
    "    sentiment = temp[2]\n",
    "\n",
    "  # Retreive only the message\n",
    "    new_msg = temp[3]\n",
    "\n",
    "    new_msg = new_msg.replace(\"hin\", \"\")\n",
    "    new_msg = new_msg.replace(\"eng\", \"\")\n",
    "    new_msg = new_msg.replace(\"o\", \"\")\n",
    "\n",
    "  # emoji removal by emoji pattern\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "    new_msg = emoji_pattern.sub(r'', new_msg)\n",
    "\n",
    "    new_msg = re.sub(' +', ' ', new_msg)\n",
    "\n",
    "    #after cleaning up, append to new list\n",
    "    tweets_clean_list_test.append(new_msg)\n",
    "    sentiments_list_test.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNEffjP82vgI"
   },
   "outputs": [],
   "source": [
    "train_dict = {\"Message\": tweets_clean_list, \"Sentiment\": sentiments_list}\n",
    "df = pd.DataFrame(train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONM-wwhE2vgK"
   },
   "source": [
    "### removing extra spaces from the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgL36DrH2vgK"
   },
   "outputs": [],
   "source": [
    "mess = []\n",
    "for message in df['Message'].values:\n",
    "    x = re.sub(' +', ' ',message)\n",
    "    z = x.lstrip()\n",
    "    y = z.rstrip()\n",
    "    mess.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvs3le_c2vgM"
   },
   "outputs": [],
   "source": [
    "df['Message_clean'] = mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjssJgnd2vgO"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Message'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Y5zkI8W42vgP",
    "outputId": "ea310ecb-43b9-4831-f5da-106a5fb1990e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>adilnisarbutt pakistan ka ghra tauq he pakista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>madarchd mulle ye mathura me nahi dikha tha ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>narendramdi manya pradhan mantri mahday shrima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>atheist krishna jcb full trend me chal rahi aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>abhisharsharma ravishkumarblg lksabha me janta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                      Message_clean\n",
       "0  negative  adilnisarbutt pakistan ka ghra tauq he pakista...\n",
       "1  negative  madarchd mulle ye mathura me nahi dikha tha ja...\n",
       "2  positive  narendramdi manya pradhan mantri mahday shrima...\n",
       "3  positive     atheist krishna jcb full trend me chal rahi aa\n",
       "4  positive  abhisharsharma ravishkumarblg lksabha me janta..."
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SGVDPYH2vgR"
   },
   "source": [
    "### for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-1NCQtM2vgR"
   },
   "outputs": [],
   "source": [
    "train_dict = {\"Message\": tweets_clean_list_test, \"Sentiment\": sentiments_list_test}\n",
    "df_test = pd.DataFrame(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izTKoPTx2vgT"
   },
   "outputs": [],
   "source": [
    "mess = []\n",
    "for message in df_test['Message'].values:\n",
    "    x = re.sub(' +', ' ',message)\n",
    "    z = x.lstrip()\n",
    "    y = z.rstrip()\n",
    "    mess.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4cGZjWo2vgV"
   },
   "outputs": [],
   "source": [
    "df_test['Message_clean'] = mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pTshdOr2vgX"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['Message'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "80WETHS82vgY",
    "outputId": "9eb64b43-5828-4135-883d-8a6440617f2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt uaapcnfessins lve lks gd n maddie ak lang b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ye ye ye we gnna start anther june n a sur nte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>zwfffy9jgklela1 min f lycg thakurdadu089 manak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>caring bht jyada caring curier wale bsdk ke si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>alihzaidipti sarfaraza 54 what nnesense kabhi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                      Message_clean\n",
       "0   neutral  rt uaapcnfessins lve lks gd n maddie ak lang b...\n",
       "1   neutral  ye ye ye we gnna start anther june n a sur nte...\n",
       "2   neutral  zwfffy9jgklela1 min f lycg thakurdadu089 manak...\n",
       "3  negative  caring bht jyada caring curier wale bsdk ke si...\n",
       "4  positive  alihzaidipti sarfaraza 54 what nnesense kabhi ..."
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QLfTOJ_82vga",
    "outputId": "c76c3af6-f51f-4dfb-cd52-f12afdb7df37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1869, 1869)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = set([])\n",
    "len(tweets_clean_list_test),len(sentiments_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJ_RK49t2vgc"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tSJAV_0R2vgd",
    "outputId": "7f0c91eb-e197-49c5-f41a-91f4ceb736cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15131/15131 [00:04<00:00, 3135.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "preprocessed_text = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(df['Message_clean'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_text.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrpIXDKB2vgf"
   },
   "outputs": [],
   "source": [
    "df['Message'] = preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8oF3veoPAO4P"
   },
   "outputs": [],
   "source": [
    "pre = preprocessed_text\n",
    "preprocessed_text = []\n",
    "for val in pre:\n",
    "    x = \"\"\n",
    "    for w in val.split(' '):\n",
    "        if len(w)>1:\n",
    "        x = x+\" \"+w\n",
    "    preprocessed_text.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mi3AjaKGAO7R"
   },
   "outputs": [],
   "source": [
    "df['single'] = preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4xfGypkx2vgj",
    "outputId": "99db2ee1-2686-4dfd-be8a-547fb12a2a61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1869/1869 [00:00<00:00, 3011.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "preprocessed_text = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(df_test['Message_clean'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_text.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEpku83T_oJ4"
   },
   "outputs": [],
   "source": [
    "df_test['Message'] = preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrX_tfWJ_u9C"
   },
   "source": [
    "## Removing all the words with single length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a59LoMpt_Lu6"
   },
   "outputs": [],
   "source": [
    "pre = preprocessed_text\n",
    "preprocessed_text = []\n",
    "for val in pre:\n",
    "  #print(val)\n",
    "    x = \"\"\n",
    "    for w in val.split(' '):\n",
    "        if len(w)>1:\n",
    "        x = x+\" \"+w\n",
    "  #print(x)\n",
    "  #break\n",
    "    preprocessed_text.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqGM7Bjt2vgl"
   },
   "outputs": [],
   "source": [
    "df_test['single'] = preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "AQNPCWkZ2vgo",
    "outputId": "7f70c181-6752-4141-f8d3-d49e33042fe3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>Message</th>\n",
       "      <th>single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rt uaapcnfessins lve lks gd n maddie ak lang b...</td>\n",
       "      <td>rt uaapcnfessins lve lks gd n maddie ak lang b...</td>\n",
       "      <td>rt uaapcnfessins lve lks gd maddie ak lang ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ye ye ye we gnna start anther june n a sur nte...</td>\n",
       "      <td>ye ye ye we gnna start anther june n a sur nte...</td>\n",
       "      <td>ye ye ye we gnna start anther june sur nte uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>zwfffy9jgklela1 min f lycg thakurdadu089 manak...</td>\n",
       "      <td>min f lycg manakgupta fficefknath mein kahna n...</td>\n",
       "      <td>min lycg manakgupta fficefknath mein kahna na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>caring bht jyada caring curier wale bsdk ke si...</td>\n",
       "      <td>caring bht jyada caring curier wale bsdk ke si...</td>\n",
       "      <td>caring bht jyada caring curier wale bsdk ke s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>alihzaidipti sarfaraza 54 what nnesense kabhi ...</td>\n",
       "      <td>alihzaidipti sarfaraza what nnesense kabhi bay...</td>\n",
       "      <td>alihzaidipti sarfaraza what nnesense kabhi ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  ...                                             single\n",
       "0   neutral  ...   rt uaapcnfessins lve lks gd maddie ak lang ba...\n",
       "1   neutral  ...   ye ye ye we gnna start anther june sur nte uh...\n",
       "2   neutral  ...   min lycg manakgupta fficefknath mein kahna na...\n",
       "3  negative  ...   caring bht jyada caring curier wale bsdk ke s...\n",
       "4  positive  ...   alihzaidipti sarfaraza what nnesense kabhi ba...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "kc5TZCuk2vgq",
    "outputId": "30592f93-e9d0-4469-a121-138944a56171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>Message</th>\n",
       "      <th>single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>adilnisarbutt pakistan ka ghra tauq he pakista...</td>\n",
       "      <td>adilnisarbutt pakistan ka ghra tauq he pakista...</td>\n",
       "      <td>adilnisarbutt pakistan ka ghra tauq he pakist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>madarchd mulle ye mathura me nahi dikha tha ja...</td>\n",
       "      <td>madarchd mulle ye mathura me nahi dikha tha ja...</td>\n",
       "      <td>madarchd mulle ye mathura me nahi dikha tha j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>narendramdi manya pradhan mantri mahday shrima...</td>\n",
       "      <td>narendramdi manya pradhan mantri mahday shrima...</td>\n",
       "      <td>narendramdi manya pradhan mantri mahday shrim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>atheist krishna jcb full trend me chal rahi aa</td>\n",
       "      <td>atheist krishna jcb full trend me chal rahi aa</td>\n",
       "      <td>atheist krishna jcb full trend me chal rahi aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>abhisharsharma ravishkumarblg lksabha me janta...</td>\n",
       "      <td>abhisharsharma ravishkumarblg lksabha me janta...</td>\n",
       "      <td>abhisharsharma ravishkumarblg lksabha me jant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  ...                                             single\n",
       "0  negative  ...   adilnisarbutt pakistan ka ghra tauq he pakist...\n",
       "1  negative  ...   madarchd mulle ye mathura me nahi dikha tha j...\n",
       "2  positive  ...   narendramdi manya pradhan mantri mahday shrim...\n",
       "3  positive  ...     atheist krishna jcb full trend me chal rahi aa\n",
       "4  positive  ...   abhisharsharma ravishkumarblg lksabha me jant...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCEjb47X2vgs"
   },
   "source": [
    "#### Applying LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdlaOBoZ2vgt"
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for k in df['single']:\n",
    "    for word in k.split(' '):\n",
    "        if word not in words:\n",
    "            words.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wR2vp6DE2vgu"
   },
   "outputs": [],
   "source": [
    "all_tweets = []\n",
    "for k in df['single']:\n",
    "    for word in k.split(' '):\n",
    "        all_tweets.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gVwUTF2s2vgv",
    "outputId": "a4a9e28c-95a5-49e0-a03f-c9437e79b308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words in thhe dataset:  37504\n",
      "Total words in the dataset:  268258\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of unique words in thhe dataset: \",len(words))\n",
    "print(\"Total words in the dataset: \",len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZ9vcKrj2vgx"
   },
   "outputs": [],
   "source": [
    "# initializing the dictionary with all unique values\n",
    "dictionary = {}\n",
    "for k in all_tweets:\n",
    "        dictionary[k] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNniyYzu2vgy"
   },
   "outputs": [],
   "source": [
    "for k in all_tweets:\n",
    "    dictionary[k] = dictionary[k]+1   # creating the dictionary from the given reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_W3zRuGT2vgz"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_dict = sorted(dictionary.items(), key=operator.itemgetter(1))  # sorting the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "YnZ7e-2n2vg1",
    "outputId": "811d0c73-10a7-48b7-c542-1a314ab79f6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 15131),\n",
       " ('ki', 4824),\n",
       " ('hai', 4464),\n",
       " ('nahi', 2872),\n",
       " ('ka', 2575),\n",
       " ('ke', 2467),\n",
       " ('rt', 2390),\n",
       " ('yu', 2284),\n",
       " ('me', 2179),\n",
       " ('se', 1987)]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = sorted_dict[::-1]   # containing all the words count in dec order\n",
    "sd[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "icsWK-RM2vg2",
    "outputId": "a8bb72ba-8880-4daa-af38-507505505564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP WORDS\t\t\tFREQUENCY\n",
      " \t\t\t\t 15131\n",
      "ki \t\t\t\t 4824\n",
      "hai \t\t\t\t 4464\n",
      "nahi \t\t\t\t 2872\n",
      "ka \t\t\t\t 2575\n",
      "ke \t\t\t\t 2467\n",
      "rt \t\t\t\t 2390\n",
      "yu \t\t\t\t 2284\n",
      "me \t\t\t\t 2179\n",
      "se \t\t\t\t 1987\n"
     ]
    }
   ],
   "source": [
    "#sd = sorted_dict[: :-1]\n",
    "print(\"TOP WORDS\\t\\t\\t\"+\"FREQUENCY\")\n",
    "count = 0\n",
    "for d in sd:\n",
    "    if count ==10:\n",
    "        break\n",
    "    print(d[0],\"\\t\\t\\t\\t\",d[1])\n",
    "    count = count+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egiZaBL12vg4"
   },
   "outputs": [],
   "source": [
    "final_words = []\n",
    "for word in sd:\n",
    "    final_words.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46kJDGcE2vg6"
   },
   "outputs": [],
   "source": [
    "## convertiing all the training set into numerical representation\n",
    "new_tweets = []   # it will contain the numerical representation of the tweets\n",
    "for f in df['single']:\n",
    "    l = []\n",
    "    for k in f.split(' '):\n",
    "        if k in final_words:\n",
    "            ind = final_words.index(k)\n",
    "            l.append(ind+1)\n",
    "    new_tweets.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buz98xQh2vg8"
   },
   "outputs": [],
   "source": [
    "## convertiing all the test set into numerical representation\n",
    "test_tweets = []   # it will contain the numerical representation of the tweets\n",
    "for f in df_test['single']:\n",
    "    l = []\n",
    "    for k in f.split(' '):\n",
    "        if k in final_words:\n",
    "            ind = final_words.index(k)\n",
    "            l.append(ind+1)\n",
    "    test_tweets.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OODuJdol2vg-"
   },
   "outputs": [],
   "source": [
    "x_train= new_tweets\n",
    "x_test=test_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "JyzogyW02vg_",
    "outputId": "0a5bdce8-0510-413f-b98a-ced116115c7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Shape (15131, 600)\n"
     ]
    }
   ],
   "source": [
    "# padding the dataset\n",
    "from keras.preprocessing import sequence\n",
    "max_review_length = 600\n",
    "x_train=sequence.pad_sequences(x_train,maxlen=max_review_length)\n",
    "x_test=sequence.pad_sequences(x_test,maxlen=max_review_length)\n",
    "print(\"Training data Shape\",x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKNgyBoq4uEX"
   },
   "outputs": [],
   "source": [
    "y_test1 = df_test['Sentiment']\n",
    "y_test = []\n",
    "for val in y_test1:\n",
    "    if val=='neutral':\n",
    "        y_test.append(1)\n",
    "    if val=='positive':\n",
    "        y_test.append(2)\n",
    "    if val=='negative':\n",
    "        y_test.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "C95qInNM5h8k",
    "outputId": "7e8c05c7-ec8b-4d10-a291-afc3d633b4f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>Message</th>\n",
       "      <th>single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>adilnisarbutt pakistan ka ghra tauq he pakista...</td>\n",
       "      <td>adilnisarbutt pakistan ka ghra tauq he pakista...</td>\n",
       "      <td>adilnisarbutt pakistan ka ghra tauq he pakist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>madarchd mulle ye mathura me nahi dikha tha ja...</td>\n",
       "      <td>madarchd mulle ye mathura me nahi dikha tha ja...</td>\n",
       "      <td>madarchd mulle ye mathura me nahi dikha tha j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>narendramdi manya pradhan mantri mahday shrima...</td>\n",
       "      <td>narendramdi manya pradhan mantri mahday shrima...</td>\n",
       "      <td>narendramdi manya pradhan mantri mahday shrim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>atheist krishna jcb full trend me chal rahi aa</td>\n",
       "      <td>atheist krishna jcb full trend me chal rahi aa</td>\n",
       "      <td>atheist krishna jcb full trend me chal rahi aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>abhisharsharma ravishkumarblg lksabha me janta...</td>\n",
       "      <td>abhisharsharma ravishkumarblg lksabha me janta...</td>\n",
       "      <td>abhisharsharma ravishkumarblg lksabha me jant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  ...                                             single\n",
       "0  negative  ...   adilnisarbutt pakistan ka ghra tauq he pakist...\n",
       "1  negative  ...   madarchd mulle ye mathura me nahi dikha tha j...\n",
       "2  positive  ...   narendramdi manya pradhan mantri mahday shrim...\n",
       "3  positive  ...     atheist krishna jcb full trend me chal rahi aa\n",
       "4  positive  ...   abhisharsharma ravishkumarblg lksabha me jant...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIQjRWvy5IGx"
   },
   "outputs": [],
   "source": [
    "y_test1 = df['Sentiment']\n",
    "y_train = []\n",
    "for val in y_test1:\n",
    "    if val=='neutral':\n",
    "        y_train.append(1)\n",
    "    if val=='positive':\n",
    "        y_train.append(2)\n",
    "    if val=='negative':\n",
    "        y_train.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7rctNM0A5TAu",
    "outputId": "e22429d8-f860-4ae8-e20f-f35c5461f169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15131, 15131)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train),len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7xs-3mg2vhA"
   },
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "#from tensorflow.python.framework import ops\n",
    "#ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "D-qKo9Bn2vhC",
    "outputId": "f2e3f412-524b-4f5b-c002-c6bbb9dae7a7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 32)           1200928   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 600, 32)           8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 600, 64)           24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,246,529\n",
      "Trainable params: 1,246,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "top_words = 37529\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=len(x_train[0])))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(Dropout(.5))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "1OJyLu2p2vhE",
    "outputId": "902a6965-6731-4a9f-deb5-42f21bb25bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 13617 samples, validate on 1514 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "13617/13617 [==============================] - 729s 54ms/step - loss: -9.1801 - acc: 0.3762 - val_loss: -16.1870 - val_acc: 0.3263\n",
      "Epoch 2/10\n",
      "13617/13617 [==============================] - 719s 53ms/step - loss: -14.3272 - acc: 0.3812 - val_loss: -17.3850 - val_acc: 0.3305\n",
      "Epoch 3/10\n",
      "13617/13617 [==============================] - 720s 53ms/step - loss: -14.4017 - acc: 0.3917 - val_loss: -17.3850 - val_acc: 0.3642\n",
      "Epoch 4/10\n",
      "13617/13617 [==============================] - 717s 53ms/step - loss: -14.4017 - acc: 0.4247 - val_loss: -17.3850 - val_acc: 0.3524\n",
      "Epoch 5/10\n",
      "13617/13617 [==============================] - 720s 53ms/step - loss: -14.4017 - acc: 0.4126 - val_loss: -17.3850 - val_acc: 0.3791\n",
      "Epoch 6/10\n",
      "13617/13617 [==============================] - 718s 53ms/step - loss: -14.4017 - acc: 0.4362 - val_loss: -17.3850 - val_acc: 0.4127\n",
      "Epoch 7/10\n",
      "13617/13617 [==============================] - 725s 53ms/step - loss: -14.4017 - acc: 0.4398 - val_loss: -17.3850 - val_acc: 0.4201\n",
      "Epoch 8/10\n",
      "13617/13617 [==============================] - 724s 53ms/step - loss: -14.4017 - acc: 0.4426 - val_loss: -17.3850 - val_acc: 0.4297\n",
      "Epoch 9/10\n",
      "13617/13617 [==============================] - 717s 53ms/step - loss: -14.4017 - acc: 0.4625 - val_loss: -17.3850 - val_acc: 0.4305\n",
      "Epoch 10/10\n",
      "13617/13617 [==============================] - 712s 52ms/step - loss: -14.4017 - acc: 0.4712 - val_loss: -17.3850 - val_acc: 0.4396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, nb_epoch=10, batch_size=64,validation_split=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xd1K4at6NDSW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.59      0.54       754\n",
      "           2       0.54      0.52      0.58       582\n",
      "           3       0.61      0.41      0.49       533\n",
      "\n",
      "    accuracy                           0.45      1869\n",
      "   macro avg       0.56      0.53      0.53      1869\n",
      "weighted avg       0.52      0.52      0.51      1869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report as report\n",
    "y_pre = model.predict_classes(X_test)\n",
    "result = report(y_test,y_pre).split(\"\\n\")\n",
    "for d in result:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F8J-SuA095eE"
   },
   "source": [
    "### taking top 5000 words for the modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mO_qyGXf97b7"
   },
   "outputs": [],
   "source": [
    "# tsking top 5000 points\n",
    "top_5000 = []\n",
    "count = 0\n",
    "for d in sd:\n",
    "    if count ==5000:\n",
    "        break\n",
    "    top_5000.append(d)\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WyUxhOp-Aw8"
   },
   "outputs": [],
   "source": [
    "top_5000[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4n3-aeK-Az0"
   },
   "outputs": [],
   "source": [
    "final_words = []\n",
    "for word in top_5000:\n",
    "    final_words.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8t9HysjH-A2h"
   },
   "outputs": [],
   "source": [
    "new_tweets = []   # it will contain the numerical representation of the reviews\n",
    "for f in df['single']:\n",
    "    l = []\n",
    "    for k in f.split(' '):\n",
    "        if k in final_words:\n",
    "            ind = final_words.index(k)\n",
    "            l.append(ind+1)\n",
    "    new_tweets.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ij_8j0Hc-A5M"
   },
   "outputs": [],
   "source": [
    "test_tweets = []   # it will contain the numerical representation of the reviews\n",
    "for f in df_test['single']:\n",
    "    l = []\n",
    "    for k in f.split(' '):\n",
    "        if k in final_words:\n",
    "            ind = final_words.index(k)\n",
    "            l.append(ind+1)\n",
    "    test_tweets.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhiVC1Z5-A8O"
   },
   "outputs": [],
   "source": [
    "# padding the dataset\n",
    "max_review_length = 600\n",
    "x_train=sequence.pad_sequences(x_train,maxlen=max_review_length)\n",
    "x_test=sequence.pad_sequences(x_test,maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF8zqNqx-A-0"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "top_words = 37529\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=len(x_train[0])))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(Dropout(.5))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05-1nPNbd1U9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 13617 samples, validate on 1514 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "13617/13617 [==============================] - 729s 54ms/step - loss: -9.1801 - acc: 0.3762 - val_loss: -16.1870 - val_acc: 0.3305\n",
      "Epoch 2/10\n",
      "13617/13617 [==============================] - 719s 53ms/step - loss: -14.3272 - acc: 0.3928 - val_loss: -17.3850 - val_acc: 0.3571\n",
      "Epoch 3/10\n",
      "13617/13617 [==============================] - 720s 53ms/step - loss: -14.4017 - acc: 0.4176 - val_loss: -17.3850 - val_acc: 0.3721\n",
      "Epoch 4/10\n",
      "13617/13617 [==============================] - 717s 53ms/step - loss: -14.4017 - acc: 0.4409 - val_loss: -17.3850 - val_acc: 0.4120\n",
      "Epoch 5/10\n",
      "13617/13617 [==============================] - 720s 53ms/step - loss: -14.4017 - acc: 0.4381 - val_loss: -17.3850 - val_acc: 0.3989\n",
      "Epoch 6/10\n",
      "13617/13617 [==============================] - 718s 53ms/step - loss: -14.4017 - acc: 0.4721 - val_loss: -17.3850 - val_acc: 0.4265\n",
      "Epoch 7/10\n",
      "13617/13617 [==============================] - 725s 53ms/step - loss: -14.4017 - acc: 0.4671 - val_loss: -17.3850 - val_acc: 0.4467\n",
      "Epoch 8/10\n",
      "13617/13617 [==============================] - 724s 53ms/step - loss: -14.4017 - acc: 0.4714 - val_loss: -17.3850 - val_acc: 0.4601\n",
      "Epoch 9/10\n",
      "13617/13617 [==============================] - 717s 53ms/step - loss: -14.4017 - acc: 0.4798 - val_loss: -17.3850 - val_acc: 0.4512\n",
      "Epoch 10/10\n",
      "13617/13617 [==============================] - 712s 52ms/step - loss: -14.4017 - acc: 0.4987 - val_loss: -17.3850 - val_acc: 0.4625\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, nb_epoch=10, batch_size=64,validation_split=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7sK9rOmd1Yo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.63      0.63       754\n",
      "           2       0.56      0.61      0.65       582\n",
      "           3       0.63      0.45      0.58       533\n",
      "\n",
      "    accuracy                           0.47      1869\n",
      "   macro avg       0.57      0.56      0.59      1869\n",
      "weighted avg       0.59      0.62      0.56      1869\n"
     ]
    }
   ],
   "source": [
    "### classical Machine Learning\n",
    "from sklearn.metrics import classification_report as report\n",
    "y_pre = model.predict_classes(X_test)\n",
    "result = report(y_test,y_pre).split(\"\\n\")\n",
    "for d in result:\n",
    "    print(d)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
